<!DOCTYPE html>
<!-- saved from url=(0034)https://songhwanjun.github.io/ -->
<html><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

<title>Hwanjun Song</title>
<meta content="Hwanjun Song" name="Hwanjun Song">
<link href="./Hwanjun_Song_files/style.css" rel="stylesheet" type="text/css">
<script src="./Hwanjun_Song_files/jquery-1.11.1.min.js" type="text/javascript"></script>  
</head>


<body>
  <div class="menu"> <a href="https://songhwanjun.github.io/index.html">Home</a>  <a href="https://songhwanjun.github.io/index.html#publications">Publications</a> <a href="https://songhwanjun.github.io/index.html#service">Services and Talks</a>
<a href="https://songhwanjun.github.io/index.html#students"> Students</a>     
  </div>
  <div class="container">
    <table border="0">
      <tbody><tr>
        <td><img src="./Hwanjun_Song_files/bio-song.jpg" width="130"></td>
        <td style="width: 10px">&nbsp;</td>
        <td valign="top" width="500">
          <span class="name">Hwanjun Song</span>
          <p class="information"><br>
           Research Scientist, <a href="https://www.amazon.science/">AWS AI Labs</a></p>
          <p class="information">Amazon Web Services Inc.<br>
            440 Terry Ave N<br>
            Seattle, WA 98109, USA</p>
          <p class="information"><strong>Email</strong>: <span class="unselectable">hwanjuns<span class="mock"></span><span class="hide">xkxkxk</span>@amazon.com</span> <span class="unselectable">/ ghkswns91<span class="mock"></span><span class="hide">xkxkxk</span>@gmail.com</span></p>
        </td>
      </tr>
    </tbody></table>
   <strong>Welcome to my page!</strong> I am a Research Scientist at the Amazon Transcribe Team of AWS AI Labs. Previsouly, I was Research Scientist at NAVER AI Lab in 2021-2022. I also graduated with my PhD in February 2021 from the Graduate School of Knowledge Service Engineering (currently, Data Science) at KAIST and worked as a research intern at Google Research, where I was fortunate to work with two supervisors, <a href="https://scholar.google.com/citations?user=h9mbv9MAAAAJ&hl=en&oi=ao"><font color="#000080">Prof. Jae-Gil Lee</font></a> and <a href="https://scholar.google.com/citations?hl=en&user=p9-ohHsAAAAJ"><font color="#000080">Prof. Ming-Hsuan Yang</font></a>. My current research interests lie in exploring the cutting-edge technologies for future AI (e.g., Data Robust/Efficient Learning, Transformers, Large Language Models) and improving the performance of AI systems under real-world scenarios related to data scale and quality.


    <a id="news" class="news"></a><span class="section">News</span> 
    <p class="news">
      <strong>Feb 2023:</strong> A Paper on 'Federated Active Learning' accepted at CVPR 2023.
    </p>  
	  <p class="news">
      <strong>Jan 2023:</strong> A Paper on 'Continual Learning' accepted at ICLR 2023.
    </p>  
    <p class="news">
      <strong>Jan 2023:</strong> A Paper on 'Data-centric AI' accepted at VLDB Journal 2023.
    </p>     
	</br>
	
    <!-- Publication session -->
    <a id="publications" class="anchor"></a><span class="section">Publications <a href="https://scholar.google.com/citations?user=Ijzuc-8AAAAJ&hl=en"> Google scholar profile </a> </span>
	An <u>underline</u> indicates the corresponding author. </br> </br>
    <table border="0" width="90%" class="paper">
	
      <tbody><font size="4.5px"><strong>2023</strong></font>
        <tr>
          <td>
            <img src="./images/pubpic/arXiv23_PrompOVD.png" class="PaperThumbnail" width="120">
          </td>
          <td bgcolor="#e9eaed">
            <u><strong>H. Song</strong></u>, <u>J. Bang</u>.  <strong>Prompt-Guided Transformers for End-to-End Open-Vocabulary Object Detection</strong>. <em></em> Preprint arXiv 2023.
            [<a href="https://arxiv.org/pdf/2303.14386.pdf"><font color="#000080">pdf</font></a>]
            [<a href="https://github.com/songhwanjun/Prompt-OVD"><font color="#000080">code</font></a>]
          </td>
        </tr>   

        <tr>
        <td>
            <img src="./images/pubpic/2023_CVPR_FAL.png" class="PaperThumbnail" width="120">
          </td>
          <td>
            S. Kim, S, Bae, <u><strong>H. Song</strong></u>, <u>SY. Yun</u>.  <strong>Re-thinking Federated Active Learning based on Inter-class Diversity</strong>. <em>International Conference on Computer Vision and Pattern Recognition </em> (CVPR) 2023. 
          </td>
        </tr>   

        <tr>
        <td>
          <img src="./images/pubpic/ICLR2023_SDP.png" class="PaperThumbnail" width="120">
        </td>
        <td bgcolor="#e9eaed">
          H. Koh, M. Seo, J. Bang, <strong>H. Song</strong>, D. Hong, S. Park, JW. Ha, <u>J. Choi</u>.  <strong>Online Boundary-Free Continual Learning by Scheduled Data Prior</strong>. <em> International Conference on Learning Representations </em> (ICLR) 2023</em> .
          [<a href="https://openreview.net/pdf?id=qco4ekz2Epm"><font color="#000080">pdf</font></a>]
        </td>
      </tr>   
	  
        <tr>
        <td>
          <img src="./images/pubpic/arXiv21_Data.jpg" class="PaperThumbnail" width="120">
        </td>
        <td>
          S. E. Whang, Y. Roh, <strong>H. Song</strong>, <u>JG. Lee</u>.  <strong>Data Collection and Quality Challenges in Deep Learning: A Data-Centric AI Perspective</strong>. <em> </em> The VLDB Journal 2023.
          [<a href="https://arxiv.org/abs/2112.06409"><font color="#000080">pdf</font></a>]
        </td>
      </tr>   
	  
	  
	</tbody></table></br>
	<font size="4.5px"><strong>2022</strong></font>
	<table border="0" width="90%" class="paper"><tbody>
	  
        <tr>
        <td bgcolor="#e9eaed">
          <img src="./images/pubpic/NIPS22_MQNet.png" class="PaperThumbnail" width="120">
        </td>
        <td bgcolor="#e9eaed">
          D. Park, Y. Shin, J. Bang, Y. Lee, <u><strong>H. Song</strong></u>, <u>JG. Lee</u>. <strong>Meta-Query-Net: Resolving Purity-Informativeness Dilemma in Open-set Active Learning</strong>. <em>Annual Conference on Neural Information Processing Systems </em> (NeurIPS) 2022. 
		  [<a href="https://scholar.google.com/citations?view_op=view_citation&hl=en&user=Ijzuc-8AAAAJ&sortby=pubdate&citation_for_view=Ijzuc-8AAAAJ:PoWvk5oyLR8C"><font color="#000080">pdf</font></a>]
		  [<a href="https://arxiv.org/pdf/2210.07805.pdf"><font color="#000080">code</font></a>]
		</td>
      </tr>
	  
        <tr>
        <td>
          <img src="./images/pubpic/arXiv_CDFSL.jpg" class="PaperThumbnail" width="120">
        </td>
        <td>
          J. Oh, S. Kim, N. Ho, JH. Kim, <u><strong>H. Song</strong></u>, <u>SY. Yun</u>. <strong>Understanding Cross-domain Few-shot Learning: An Experimental Study</strong>. <em>Annual Conference on Neural Information Processing Systems </em> (NeurIPS) 2022. 
		  [<a href="https://scholar.google.com/citations?view_op=view_citation&hl=en&user=Ijzuc-8AAAAJ&sortby=pubdate&citation_for_view=Ijzuc-8AAAAJ:PoWvk5oyLR8C"><font color="#000080">pdf</font></a>]
		  [<a href="https://anonymous.4open.science/r/understandingCDFSL"><font color="#000080">code</font></a>]
		</td>
      </tr>
	  
        <tr>
        <td bgcolor="#e9eaed">
          <img src="./images/pubpic/ICDM22_PINCETTE.png" class="PaperThumbnail" width="120">
        </td>
        <td bgcolor="#e9eaed">
          D. Park, J. Kang, <strong>H. Song</strong>, S. Yoon, <u>JG Lee</u>. <strong>Multi-view POI-level Cellular Trajectory Reconstruction for Digital Contact Tracing of Infectious Diseases</strong>. <em> International Conference on Data Minig </em> (ICDM) 2022. 
		</td>
      </tr>
	  
        <tr>
        <td>
          <img src="./images/pubpic/CIKM22_FedRN.png" class="PaperThumbnail" width="120">
        </td>
        <td>
          S. Kim, W. Shin, S. Jang, <u><strong>H. Song</strong></u>, <u>SY. Yun</u>. <strong>FedRN: Exploiting k-Reliable Neighbors Towards Robust Federated Learning</strong>. <em> International Conference on Information and Knowledge Management </em> (CIKM) 2022. 
		  [<a href="https://arxiv.org/abs/2205.01310"><font color="#000080">pdf</font></a>]
		</td>
      </tr>
	  
        <tr>
        <td bgcolor="#e9eaed">
          <img src="./images/pubpic/arXiv22_eCLIP.jpg" class="PaperThumbnail" width="120">
        </td>
        <td bgcolor="#e9eaed">
          W. Shin, J. Park, T. Woo, Y. Cho, K. Oh, <u><strong>H. Song</strong></u>. <strong>e-CLIP: Large-Scale Vision-Language Representation Learning in E-commerce</strong>. <em> International Conference on Information and Knowledge Management </em> (CIKM) 2022. <span class="oral">The first large-scale industry study investigating a unified multimodal transformer model.</span> 
		  [<a href="https://arxiv.org/abs/2207.00208"><font color="#000080">pdf</font></a>]
		</td>
      </tr>
	  
        <tr>
        <td>
          <img src="./images/pubpic/ICMLW22_ReFine.jpg" class="PaperThumbnail" width="120">
        </td>
        <td>
          J. Oh, S. Kim, N. Ho, JH. Kim, <u><strong>H. Song</strong></u>, <u>SY. Yun</u>.  <strong>ReFine: Re-randomization before Fine-tuning for Cross-domain Few-shot Learning</strong>. <em> International Conference on Information and Knowledge Management </em> (CIKM) 2022. </br>This paper was also presented at ICML UpML workshop, 2022.
		  [<a href="https://arxiv.org/abs/2205.05282"><font color="#000080">pdf</font></a>]
        </td>
      </tr>   
	  
        <tr>
        <td>
          <img src="./images/pubpic/arXiv22_ViDTPlus.jpg" class="PaperThumbnail" width="120">
        </td>
        <td  bgcolor="#e9eaed">
          <u><strong>H. Song</strong></u>, D. Sun, S. Chun, V. Jampani, D. Han, B. Heo, W. Kim, and <u>M-H Yang</u>.  <strong>An Extendable, Efficient and Effective Transformer-based Object Detector</strong>. <em> </em> Preprint arXiv 2022. <span class="oral">An extended version of ViDT to support multi-task learning.</span>
          [<a href="https://arxiv.org/abs/2204.07962"><font color="#000080">pdf</font></a>]
          [<a href="https://github.com/naver-ai/vidt"><font color="#000080">code</font></a>]
        </td>
      </tr>   
	  
        <tr>
        <td>
          <img src="./images/pubpic/ICMLW22_LG-FAL.jpg" class="PaperThumbnail" width="120">
        </td>
        <td>
          S. Kim, S. Bae, <u><strong>H. Song</strong></u>, <u>SY. Yun</u>.  <strong>LG-FAL: Federated Active Learning Strategy using Local and Global Models</strong>. <em>International Conference on Machine Learning </em> (ReALML Workshop) 2022. 
        </td>
      </tr>   
	  
        <tr>
        <td>
          <img src="./images/pubpic/ICML22_TIME.jpg" class="PaperThumbnail" width="120">
        </td>
        <td bgcolor="#e9eaed">
          S. Yun, J. Kim, D. Han, <strong>H. Song</strong>, JW. Ha, <u>J. Shin</u>.  <strong>Time Is MattEr: Temporal Self-supervision for Video Transformers</strong>. <em>International Conference on Machine Learning </em> (ICML) 2022. <span class="oral">Short Presentation.</span>
        </td>
      </tr>   

  
        <tr>
        <td>
          <img src="./images/pubpic/ICML22_MultiFormation.jpg" class="PaperThumbnail" width="120">
        </td>
        <td>
          JH. Kim, J. Kim, SJ. Oh, S. Yun, <strong>H. Song</strong>, J. Jeong, JW. Ha, <u>HO. Song</u>.  <strong>Dataset Condensation via Efficient Synthetic-Data Parameterization</strong>. <em>International Conference on Machine Learning </em> (ICML) 2022. <span class="oral">Short Presentation.</span>
          [<a href="https://arxiv.org/abs/2205.14959"><font color="#000080">pdf</font></a>]
          [<a href="https://github.com/snu-mllab/Efficient-Dataset-Condensation"><font color="#000080">code</font></a>]
        </td>
      </tr>   

  
        <tr>
        <td>
          <img src="./images/pubpic/CVPR22_PuriDiver.jpg" class="PaperThumbnail" width="120">
        </td>
        <td bgcolor="#e9eaed">
          J. Bang, H. Koh, S. Park, <strong>H. Song</strong>, JW. Ha, <u>J. Choi</u>.  <strong>Online Continual Learning on a Contaminated Data Stream with Blurry Task Boundaries</strong>. <em>International Conference on Computer Vision and Pattern Recognition </em> (CVPR) 2022. 
          [<a href="https://openaccess.thecvf.com/content/CVPR2022/papers/Bang_Online_Continual_Learning_on_a_Contaminated_Data_Stream_With_Blurry_CVPR_2022_paper.pdf"><font color="#000080">pdf</font></a>]
          [<a href="https://github.com/clovaai/puridiver"><font color="#000080">code</font></a>]
        </td>
      </tr>   

  
        <tr>
        <td>
          <img src="./images/pubpic/TNNLS22_Survey.jpg" class="PaperThumbnail" width="120">
        </td>
        <td>
          <strong>H. Song</strong>, M. Kim, D. Park, Y. Shin, <u>JG. Lee</u>.  <strong>Learning from Noisy Labels with Deep Neural Networks: A Survey</strong>. <em>IEEE Transactions on Neural Networks and Learning Systems</em> (TNNLS) 2022. <span class="oral">The most cited survey paper on handling noisy labels with DNNs.</span>
          [<a href="https://arxiv.org/abs/2007.08199"><font color="#000080">pdf</font></a>]
          [<a href="https://github.com/songhwanjun/Awesome-Noisy-Labels"><font color="#000080">code</font></a>]
        </td>
      </tr>   


        <tr>
        <td>
          <img src="./images/pubpic/ICLR22_ViDT.png" class="PaperThumbnail" width="120">
        </td>
        <td bgcolor="#e9eaed">
          <u><strong>H. Song</strong></u>, D. Sun, S. Chun, V. Jampani, D. Han, B. Heo, W. Kim, and M-H Yang.  <strong>ViDT: An Efficient and Effective Fully Transformer-based Object Detector</strong>. <em>International Conference on Learning Representations </em> (ICLR) 2022. 
          [<a href="https://arxiv.org/pdf/2110.03921.pdf"><font color="#000080">pdf</font></a>]
          [<a href="https://github.com/naver-ai/vidt"><font color="#000080">code</font></a>]
        </td>
      </tr>   

  
        <tr>
        <td>
          <img src="./images/pubpic/ICLR22_TCLP.png" class="PaperThumbnail" width="120">
        </td>
        <td>
          Y. Shin, S. Yoon, S. Kim, <strong>H. Song</strong>, <u>JG. Lee, B</u>. S. Lee.  <strong>Coherence-based Label Propagation over Time Series for Accelerated Active Learning</strong>. <em>International Conference on Learning Representations </em> (ICLR) 2022. 
          [<a href="https://openreview.net/pdf?id=gjNcH0hj0LM"><font color="#000080">pdf</font></a>]
          [<a href="https://www.%20dropbox.com/sh/chmh8fyal7ip1lc/AAAgy8kZ49LxxO6EHIBLyGzqa?dl=0"><font color="#000080">code</font></a>]
        </td>
      </tr>   

  
        <tr>
        <td>
          <img src="./images/pubpic/AAAI22_MELON.png" class="PaperThumbnail" width="120">
        </td>
        <td bgcolor="#e9eaed">
          M. Kim, <strong>H. Song</strong>, Y. Shin, D. Park, K. Shin, <u>JG. Lee</u>.  <strong>Meta-Learning for Online Update of Recommender Systems</strong>. <em>The AAAI Conference on Artificial Intelligence </em> (AAAI) 2022. 
          [<a href="https://www.aaai.org/AAAI22Papers/AAAI-2570.KimM.pdf"><font color="#000080">pdf</font></a>]
        </td>
      </tr>   

  
        <tr>
        <td>
          <img src="./images/pubpic/AAAI22_COVID.png" class="PaperThumbnail" width="120">
        </td>
        <td>
          D. Kim, H. Min, Y. Nam, <strong>H. Song</strong>, S. Yoon, M. Kim, <u>JG. Lee</u>.  <strong>COVID-EENet: Predicting Fine-Grained Impact of COVID-19 on Local Economies </strong>. <em>The AAAI Conference on Artificial Intelligence </em> (AAAI) 2022. <span class="oral">Oral Presentation.</span>
          [<a href="https://www.aaai.org/AAAI22Papers/AISI-1959.KimD.pdf"><font color="#000080">pdf</font></a>]
          [<a href="https://github.com/kaist-dmlab/COVID-EENet"><font color="#000080">code</font></a>]
        </td>
      </tr>   
	</tbody></table></br>
	<font size="4.5px"><strong>2021</strong></font>
	<table border="0" width="90%" class="paper"><tbody>
	  
        <tr>
        <td>
          <img src="./images/pubpic/BMVC21_MEDUSA.png" class="PaperThumbnail" width="120">
        </td>
        <td>
          <strong>H. Song</strong>, E. Kim, V. Jampani, D. Sun, <u>M-H. Yang</u>.  <strong>Exploiting Scene Depth for Object Detection with Multimodal Transformers</strong>. <em>British Machine Vision Conference </em> (BMVC) 2021. 
          [<a href="https://www.bmvc2021-virtualconference.com/assets/papers/0568.pdf"><font color="#000080">pdf</font></a>]
          [<a href="https://github.com/songhwanjun/MEDUSA"><font color="#000080">code</font></a>]
        </td>
      </tr>   

  
        <tr>
        <td>
          <img src="./images/pubpic/NeurIPS21_TAUFE.png" class="PaperThumbnail" width="120">
        </td>
        <td bgcolor="#e9eaed">
          D. Park, <strong>H. Song</strong>, M. Kim, <u>JG. Lee</u>.  <strong>Task-Agnostic Undesirable Feature Deactivation Using Out-of-Distribution Data</strong>. <em>Annual Conference on Neural Information Processing Systems </em> (NeurIPS) 2021. 
          [<a href="https://github.com/songhwanjun/songhwanjun.github.io/blob/main/files/2021_NeurIPS_TAUFE.pdf"><font color="#000080">pdf</font></a>]
          [<a href="https://github.com/kaist-dmlab/TAUFE"><font color="#000080">code</font></a>]
        </td>
      </tr>   

  
        <tr>
        <td>
          <img src="./images/pubpic/KDD21_MORPH.png" class="PaperThumbnail" width="120">
        </td>
        <td>
          <strong>H. Song</strong>, M. Kim, D. Park, Y. Shin, <u>JG. Lee</u>.  <strong>Robust Learning by Self-Transition for Handling Noisy Labels</strong>. <em>International Conference on Knowledge Discovery and Data Mining </em> (KDD) 2021. <span class="oral">Oral Presentation.</span>
          [<a href="https://github.com/songhwanjun/songhwanjun.github.io/blob/main/files/2021_KDD__MORPH.pdf"><font color="#000080">pdf</font></a>]
        </td>
      </tr>   

  
        <tr>
        <td>
          <img src="./images/pubpic/KDD21_Tutorial.png" class="PaperThumbnail" width="120">
        </td>
        <td bgcolor="#e9eaed">
          JG. Lee, Y. Roh, <u>S. E. Whang</u>. <strong>Machine Learning Robustness, Fairness, and their Convergence</strong>. </strong>. <em>International Conference on Knowledge Discovery and Data Mining </em>(KDD) 2021. <span class="oral">2+ Hour Live Tutorial.</span>
		  [<a href="https://www.youtube.com/playlist?list=PLHULDvHaIwSwnbwkAOrJSs_TMQl1nhZ72"><font color="#000080">webpage</font></a>]
          [<a href="https://github.com/songhwanjun/songhwanjun.github.io/blob/main/files/2021_KDD_Tutorial.pdf"><font color="#000080">pdf</font></a>]
		  [<a href="https://www.youtube.com/playlist?list=PLHULDvHaIwSwnbwkAOrJSs_TMQl1nhZ72"><font color="#000080">video</font></a>]
		  [<a href="https://docs.google.com/presentation/d/1mV6oF_boGtnk14qh64Y4DaiKstcGJIfZiw-5AgTTgVQ/edit#slide=id.ge241072c6d_0_0"><font color="#000080">slide</font></a>]
		  

        </td>
      </tr>   

  
        <tr>
        <td>
          <img src="./images/pubpic/AAAI20_PREMERE.png" class="PaperThumbnail" width="120">
        </td>
        <td>
          M. Kim, <strong>H. Song</strong>, D. Kim, K. Shin, <u>JG. Lee</u>.  <strong>PREMERE: Meta-Reweighting via Self-Ensembling for Point-of-Interest Recommendation</strong>. <em>The AAAI Conference on Artificial Intelligence </em> (AAAI) 2021. <span class="oral">Oral Presentation.</span>
          [<a href="https://github.com/songhwanjun/songhwanjun.github.io/blob/main/files/2021_AAAI_PREMERE.pdf"><font color="#000080">pdf</font></a>]
          [<a href="https://github.com/kaist-dmlab/PREMERE"><font color="#000080">code</font></a>]
        </td>
      </tr>   
	</tbody></table></br>
	<font size="4.5px"><strong>2020</strong></font>
	<table border="0" width="90%" class="paper"><tbody>
        <tr>
        <td>
          <img src="./images/pubpic/CIKM20_Recency.png" class="PaperThumbnail" width="120">
        </td>
        <td bgcolor="#e9eaed">
          <strong>H. Song</strong>, M, Kim, S. Kim, <u>JG. Lee</u>.  <strong>Carpe Diem, Seize the Samples Uncertain "At the Moment" for Adaptive Batch Selection</strong>. <em>International Conference on Information and Knowledge Management </em> (CIKM) 2020. <span class="oral">Oral Presentation.</span>
          [<a href="https://dl.acm.org/doi/abs/10.1145/3340531.3411898"><font color="#000080">pdf</font></a>]
          [<a href="https://github.com/kaist-dmlab/RecencyBias"><font color="#000080">code</font></a>]
        </td>
      </tr>   
	  
	  
        <tr>
        <td>
          <img src="./images/pubpic/ML20_ADA.png" class="PaperThumbnail" width="120">
        </td>
        <td>
          <strong>H. Song</strong>, S. Kim, M. Kim, <u>JG. Lee</u>.  <strong>Ada-Boundary: Accelerating DNN Training via Adaptive Boundary Batch Selection</strong>. <em>Machine Learning </em> (ML) 2020. <span class="oral">Invited Paper and Oral Presentation at ECML-PKDD 2020.</span>
          [<a href="https://link.springer.com/article/10.1007/s10994-020-05903-6"><font color="#000080">pdf</font></a>]
          [<a href="https://github.com/kaist-dmlab/Ada-Boundary"><font color="#000080">code</font></a>]
        </td>
      </tr>   

  
        <tr>
        <td>
          <img src="./images/pubpic/KDD20_HiCOVID.png" class="PaperThumbnail" width="120">
        </td>
        <td bgcolor="#e9eaed">
          M. Kim, J. Kang, Dim, <strong>H. Song</strong>, H. Min, Y. Nam, D. Park, <u>JG. Lee</u>.  <strong>Hi-COVIDNet: Deep Learning Approach to Predict Inbound COVID-19 Patients and Case Study in South Korea </strong>. <em>International Conference on Knowledge Discovery and Data Mining </em> (KDD) 2020. <span class="oral">Oral Presentation.</span>
          [<a href="https://dl.acm.org/doi/10.1145/3394486.3412864"><font color="#000080">pdf</font></a>]
          [<a href="https://github.com/kaist-dmlab/Hi-COVIDNet"><font color="#000080">code</font></a>]
        </td>
      </tr>   

        <tr>
        <td>
          <img src="./images/pubpic/ICMLW20_Early.png" class="PaperThumbnail" width="120">
        </td>
        <td>
          <strong>H. Song</strong>, M. Kim, D. Park, <u>JG. Lee</u>.  <strong>How Does Early Stopping Help Generalization against Label Noise? </strong>. <em>International Conference on Machine Learning </em> (UDL Workshop) 2020. 
          [<a href="http://www.gatsby.ucl.ac.uk/~balaji/udl2020/accepted-papers/UDL2020-paper-020.pdf"><font color="#000080">pdf</font></a>]
          [<a href="https://bit.ly/2l3g9Jx"><font color="#000080">code</font></a>]
        </td>
      </tr>   
	  
        <tr>
        <td>
          <img src="./images/pubpic/PAKDD20_Revisit.png" class="PaperThumbnail" width="120">
        </td>
        <td bgcolor="#e9eaed">
          S. Kim, <strong>H. Song</strong>, S. Kim, B. Kim, <u>JG. Lee</u>.  <strong>Revisit Prediction by Deep Survival Analysis</strong>. <em>Pacific-Asia Conference on Knowledge Discovery and Data Mining </em> (PAKDD) 2020. 
          [<a href="https://dm.kaist.ac.kr/lab/papers/pakdd20.pdf"><font color="#000080">pdf</font></a>]
        </td>
      </tr>   

  
        <tr>
        <td>
          <img src="./images/pubpic/WWW20_Embed.png" class="PaperThumbnail" width="120">
        </td>
        <td>
          D. Park, <strong>H. Song</strong>, M. Kim, <u>JG. Lee</u>.  <strong>TRAP: Two-level Regularized Autoencoder-based Embedding for Power-law Distributed Data</strong>. <em>TheWebConf </em> (WWW) 2020. <span class="oral">Oral Presentation.</span>
          [<a href="http://dm.kaist.ac.kr/lab/papers/webconf20.pdf"><font color="#000080">pdf</font></a>]
          [<a href="https://github.com/kaist-dmlab/TRAP"><font color="#000080">code</font></a>]
        </td>
      </tr>   

	</tbody></table></br>
	<font size="4.5px"><strong>2019</strong></font>
	<table border="0" width="90%" class="paper"><tbody>
        <tr>
        <td>
          <img src="./images/pubpic/KDDW20_MLAT.png" class="PaperThumbnail" width="120">
        </td>
        <td bgcolor="#e9eaed">
          D. Park, S. Yoon, <strong>H. Song</strong>, <u>JG. Lee</u>.  <strong>MLAT: Metric Learning for kNN in Streaming Time Series</strong>. <em>International Conference on Knowledge Discovery and Data Mining </em> (MileTs Workshop) 2019. 
          [<a href="https://arxiv.org/pdf/1910.10368.pdf"><font color="#000080">pdf</font></a>]
        </td>
      </tr>   

  
        <tr>
        <td>
          <img src="./images/pubpic/ICML19_SELFIE.png" class="PaperThumbnail" width="120">
        </td>
        <td>
          <strong>H. Song</strong>, M. Kim, <u>JG. Lee</u>.  <strong>SELFIE: Refurbishing Unclean Samples for Robust Deep Learning</strong>. <em>International Conference on Machine Learning </em> (ICML) 2019. <span class="oral">Short Presentation.</span>
          [<a href="http://proceedings.mlr.press/v97/song19b.html"><font color="#000080">pdf</font></a>]
          [<a href="https://github.com/kaist-dmlab/SELFIE"><font color="#000080">code</font></a>]
          [<a href="https://dm.kaist.ac.kr/datasets/animal-10n/"><font color="#000080">dataset</font></a>]
        </td>
      </tr>   
	</tbody></table></br>
	<font size="4.5px"><strong>2018</strong></font>
	<table border="0" width="90%" class="paper"><tbody>
        <tr>
        <td>
          <img src="./images/pubpic/SIGMOD18_RPDBSCAN.png" class="PaperThumbnail" width="120">
        </td>
        <td bgcolor="#e9eaed">
          <strong>H. Song</strong>, <u>JG. Lee</u>.  <strong>RP-DBSCAN: A Superfast Parallel DBSCAN Algorithm based on Random Partitioning</strong>. <em>International Conference on Management of Data </em> (SIGMOD) 2018. <span class="oral">Top 2% of the submitted papers (accepted without revision round). Oral Presentation.</span><span class="oral"></span>
          [<a href="https://dm.kaist.ac.kr/jaegil/papers/sigmod18.pdf"><font color="#000080">pdf</font></a>]
          [<a href="https://github.com/kaist-dmlab/RP-DBSCAN"><font color="#000080">code</font></a>]
        </td>
      </tr>   
	</tbody></table>
	<font size="4.5px"><strong>2017</strong></font>
	<table border="0" width="90%" class="paper"><tbody>
        <tr>
        <td>
          <img src="./images/pubpic/KDD17_PAMAE.png" class="PaperThumbnail" width="120">
        </td>
        <td>
          <strong>H. Song</strong>, <u>JG. Lee</u>, WS. Han.  <strong>PAMAE: Parallel k-Medoids Clustering with High Accuracy and Efficiency</strong>. <em>International Conference on Knowledge Discovery and Data Mining </em> (KDD) 2017. <span class="oral">Selected one of the outstanding research among Microsoft Azure Supporting Projects.</span>
          [<a href="https://www.microsoft.com/en-us/research/lab/microsoft-research-asia/articles/using-microsoft-azure-research-tool-scalable-data-mining-2/"><font color="#000080">blog</font></a>]
          [<a href="http://dm.kaist.ac.kr/lab/papers/kdd17.pdf"><font color="#000080">pdf</font></a>]
          [<a href="https://github.com/kaist-dmlab/k-Medoid"><font color="#000080">code</font></a>]
        </td>
      </tr>   
	  
    </tbody></table>

    <p>&nbsp;</p>

	 
    <a id="service" class="anchor"></a><span class="section">Services</span>
    <p class="service">
      Co-organized Workshop on  <a href="https://kdd21tutorial-robust-fair-learning.github.io/"> Machine Learning Robustness, Fairness, and their Convergence </a> at KDD 2021
    </p>   
    <p class="service">Reviewer for ICML, NeurIPS, ICLR, CVPR, ICCV, ECCV, PAMI, IJCV, TNNLS since 2020
	</p>    
    <p class="service"></br><strong> Seminar / Techtalk </strong></br> 
	</br>
	Data Robustness and Efficiency, Vision Transformers, and Continual Learning, GIST and IEEE Seminar, Dec 2022  [<a href="https://drive.google.com/file/d/1JpwPDHPPG19G1Uz2EzS_GxU3_fgsiK3Z/view?usp=sharing"><font color="#000080">slides</font></a>]</br>
	ML Robustness against Label Noise, UNIST Graduate School of AI, Sep 2022 </br>
	Robust Deep Learning and Extension to Real-world Applications, Database Society Summer School, Aug 2022 </br>
	An Extendable, Efficient and Effective Tranformer-based Object Detector, NAVER CLOVA, Jun 2022 </br>
	ML Robustness against Label Noise, Amazon AWS AI / Responsible AI, Mar 2022 </br>
	Transformers for Computer Vision, Electronics and Telecommunications Research Institute, Feb 2022</br>
	Machine Learning Robustness, Fairness, and their Convergence, KDD Tutorial, Aug 2021</br>
	Robust Learning by Self-transition for Handling Noisy Labels, NAVER CLOVA, May 2021</br>
	Learning from Noisy Labels for Classification, Google Research, May 2021</br>
	Exploiting Scene Depth for Object Detection, Google Research & NAVER AI Lab, Dec 2020</br>
	Robust Learning under Label Noise, Institute of Basic Science, Dec 2019 </br>
	Parallel Clustering and Large-Scale Data Analytics, NAVER CLOVA, Aug 2018 </br>
	</p>    	
    <p>&nbsp;</p>
  

<a id="students" class="anchor"></a><span class="section">Students </span>

<p> <font color="#444444" face="Arial" size="2"> I have been fortunate to work with many gifted students:</font> </p>
  <ul>
  <font color="#444444" face="Arial" size="2">    
  <li> <a href="https://minseokkim.net/"> Minseok Kim </a> (KAIST â†’ Amazon Alexa), 2019-2022  </li>
  <li> <a href="https://scholar.google.com/citations?hl=en&user=4xXYQl0AAAAJ"> Dongmin Park </a> (KAIST), 2020-2022  </li>
  <li> <a href="https://scholar.google.com/citations?hl=en&user=b4_yMt4AAAAJ"> Yooju Shin </a> (KAIST), 2020-2022  </li>
  <li> <a href="https://scholar.google.com/citations?hl=en&user=vEAbNDYAAAAJ"> Doyoung Kim </a> (KAIST), 2020-2022  </li>
  <li> <a href="https://scholar.google.com/citations?hl=ko&user=YjpFRuIAAAAJ"> Sangmook Kim </a> (KAIST), 2021-2022 </li>
  <li> <a href="https://scholar.google.com/citations?user=_Q8obn0AAAAJ&hl=ko"> Jaehoon Oh </a> (KAIST), 2021-2022  </li>
  <li> <a href="https://scholar.google.com/citations?hl=ko&user=6Wh4hxcAAAAJ"> Seulki Park </a> (Seoul National University), 2021-2022  </li>
  <li> <a href="https://scholar.google.com/citations?user=nS24h74AAAAJ&hl=en"> Saehyung Lee </a> (Seoul National University), 2022  </li>
  <li> <a href="https://www.linkedin.com/in/sangmin-bae-770b1321a/?originalSubdomain=kr"> Sangmin Bae </a> (KAIST), 2022 </li>
  <li> <a href="https://scholar.google.com/citations?user=wleS-UQAAAAJ&hl=en&oi=ao"> Dahuin Jung </a> (Seoul National University), 2022 </li>
  </font>
  </ul>

  <p><font color="#444444" face="Arial" size="2">&copy 2022 Hwanjun Song Thanks <a href="https://deqings.github.io/"><font color="#000080">Dr. Deqing Sun</font></a> and <a href="http://people.csail.mit.edu/celiu"><font color="#000080">Dr. Ce Liu</font></a> for the template. </font></p>

  </div>
  <script>
    var thumbnails = document.getElementsByClassName("PaperThumbnail");
    var i;
    for (i = 0; i < thumbnails.length; i++) {
      thumbnails[i].width = "120"
    }
  </script>  


</body></html>
